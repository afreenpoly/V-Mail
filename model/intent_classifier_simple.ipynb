{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, AdamW, get_scheduler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_metric\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classifier = torch.nn.Linear(model.config.hidden_size, 10)\n",
    "model.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"dataset_sheet.csv\", split='train')\n",
    "dataset = dataset.class_encode_column(\"label\")\n",
    "full_dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1f8543f1e84a21b9e42d85e68518a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edd12a6d7a74461b2e41ab39b478374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"prompt\"], truncation=True, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "tokenized_datasets = full_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"prompt\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aadil Sayad\\Documents\\Local Disk D (real)\\Projects\\V_Mail\\.venv\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf399de05a744d6991485bda360a79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=0.00005)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar.clear()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sum = 0\n",
    "accuracy_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aadil Sayad\\AppData\\Local\\Temp\\ipykernel_11036\\183604491.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"f1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.875\n",
      "1.0\n",
      "0.9166666666666666\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.925\n",
      "1.0\n",
      "0.875\n",
      "1.0\n",
      "0.8749999999999999\n",
      "1.0\n",
      "0.8333333333333333\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    current_accuracy = metric.compute(predictions=predictions, references=batch[\"labels\"], average=\"weighted\")\n",
    "    print(current_accuracy['f1'])\n",
    "    accuracy_sum += current_accuracy['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.175\n",
      "0.9670000000000001\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_sum)\n",
    "accuracy_avg = accuracy_sum / 25\n",
    "print(accuracy_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_to_text = {0: \"forward\", 1: \"list\", 2: \"read\", 3: \"reply\", 4: \"send\", 5: \"star\", 6: \"trash\", 7: \"trash_list\", 8: \"unknown\", 9: \"untrash\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write a new mail -> 4\n",
      "delete this mail -> 6\n",
      "mark this mail as important -> 5\n",
      "read this mail -> 2\n",
      "show inbox -> 1\n",
      "list trash mails -> 7\n",
      "please untrash this mail -> 9\n",
      "The weather is nice today. -> 8\n",
      "i'd like to reply to this mail -> 3\n",
      "Please forward this mail -> 0\n"
     ]
    }
   ],
   "source": [
    "example_inputs = [\"write a new mail\", \"delete this mail\", \"mark this mail as important\", \"read this mail\", \"show inbox\", \"list trash mails\", \"please untrash this mail\", \"The weather is nice today.\", \"i'd like to reply to this mail\", \"Please forward this mail\"]\n",
    "for example_input in example_inputs:\n",
    "    encoded_input = tokenizer(example_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "        logits = output.logits\n",
    "        predicted_intent = logits.argmax(-1).item()\n",
    "        print(f\"{example_input} -> {predicted_intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained_tokenizer_new\\\\tokenizer_config.json',\n",
       " 'trained_tokenizer_new\\\\special_tokens_map.json',\n",
       " 'trained_tokenizer_new\\\\vocab.txt',\n",
       " 'trained_tokenizer_new\\\\added_tokens.json',\n",
       " 'trained_tokenizer_new\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"trained_model_new\")\n",
    "tokenizer.save_pretrained(\"trained_tokenizer_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = AutoModelForSequenceClassification.from_pretrained(\"trained_model_new\")\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(\"trained_tokenizer_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trash this mail now. -> trash\n"
     ]
    }
   ],
   "source": [
    "example_input = \"Trash this mail now.\"\n",
    "encoded_input = tokenizer(example_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_input)\n",
    "    logits = output.logits\n",
    "    predicted_intent = logits.argmax(-1).item()\n",
    "    print(f\"{example_input} -> {output_to_text[predicted_intent]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
